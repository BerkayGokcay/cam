# =============================
# File: worker.py (RabbitMQ consumer + minibatch + MinIO I/O)
# =============================
#!/usr/bin/env python3
import os, time, cv2, json, queue, threading
import numpy as np
from io import BytesIO
from typing import List, Tuple

import pika
from minio import Minio
import onnxruntime
import face_alignment

# ---------------------- Konfig ----------------------------
MINIO_BUCKET = os.getenv("MINIO_BUCKET", "videos-face-detection-v2")
MINIO_HOST = os.getenv("MINIO_HOST","127.0.0.1")
MINIO_PORT = os.getenv("MINIO_PORT","9000")
MINIO_USER = os.getenv("MINIO_USER","minioadmin")
MINIO_PASS = os.getenv("MINIO_PASS","minioadmin")
RAW_PREFIX    = os.getenv("RAW_PREFIX", "raw-crops/")
PROCESSED_PREFIX = os.getenv("PROCESSED_PREFIX", "processed/")

RMQ_URL   = os.getenv("RMQ_URL", "amqp://guest:guest@127.0.0.1:5672/%2F")
RMQ_QUEUE = os.getenv("RMQ_QUEUE", "faces")

BATCH_SIZE = int(os.getenv("BATCH", "16"))
MAX_WAIT_MS = int(os.getenv("MAX_WAIT_MS", "8"))
GPU_ID = int(os.getenv("GPU_ID","0"))
ARCFACE_MODEL = os.getenv("ARCFACE_MODEL", "/opt/models/recognition/w600k_r50.onnx")

# ---------------------- MinIO -----------------------------
minio_client = Minio(f"{MINIO_HOST}:{MINIO_PORT}", access_key=MINIO_USER, secret_key=MINIO_PASS, secure=False)
if not minio_client.bucket_exists(MINIO_BUCKET):
    minio_client.make_bucket(MINIO_BUCKET)

# ---------------------- RabbitMQ --------------------------
params = pika.URLParameters(RMQ_URL)
rmq_conn = pika.BlockingConnection(params)
rmq_chan = rmq_conn.channel()
rmq_chan.queue_declare(queue=RMQ_QUEUE, durable=False)
rmq_chan.basic_qos(prefetch_count=BATCH_SIZE)

job_q: "queue.Queue[Tuple[str,np.ndarray, int]]" = queue.Queue(maxsize=1024)

# ---------------------- Models ----------------------------
fa = face_alignment.FaceAlignment(face_alignment.LandmarksType.TWO_D, device="cuda")

class ArcFaceONNX:
    def __init__(self, model_path: str, gpu_id: int = 0):
        providers = [
            ("TensorrtExecutionProvider", {"device_id": gpu_id}),
            ("CUDAExecutionProvider", {"device_id": gpu_id}),
            "CPUExecutionProvider",
        ]
        so = onnxruntime.SessionOptions()
        so.intra_op_num_threads = 1
        self.session = onnxruntime.InferenceSession(model_path, sess_options=so, providers=providers)
        self.in_name = self.session.get_inputs()[0].name
        self.out_name = self.session.get_outputs()[0].name
        ishape = self.session.get_inputs()[0].shape
        self.H = int(ishape[2] if ishape[2] not in (None, 'None', -1) else 112)
        self.W = int(ishape[3] if ishape[3] not in (None, 'None', -1) else 112)

    def preprocess_batch(self, crops: List[np.ndarray]) -> np.ndarray:
        arr = []
        for im in crops:
            x = cv2.resize(im, (self.W, self.H), interpolation=cv2.INTER_AREA)
            x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB).astype(np.float32)
            x = (x - 127.5) / 127.5
            x = x.transpose(2,0,1)
            arr.append(x)
        return np.stack(arr, axis=0)

    def infer(self, crops: List[np.ndarray]) -> np.ndarray:
        if not crops:
            return np.empty((0,128), dtype=np.float32)
        inp = self.preprocess_batch(crops)
        out = self.session.run([self.out_name], {self.in_name: inp})[0]
        norms = np.linalg.norm(out, axis=1, keepdims=True) + 1e-9
        return (out / norms).astype(np.float32)

arc = ArcFaceONNX(ARCFACE_MODEL, gpu_id=GPU_ID)

class GPUFaceAligner:
    def __init__(self, crop_size: int = 112):
        self.crop_size = crop_size
        self.std = np.array([
            [38.2946, 51.6963], [73.5318, 51.5014], [56.0252, 71.7366], [41.5493, 92.3655], [70.7299, 92.2041]
        ], dtype=np.float32)
        self.idx5 = [36,45,33,48,54]
    def align_face(self, img_bgr: np.ndarray, lm68: np.ndarray) -> np.ndarray | None:
        try:
            lm5 = lm68[self.idx5].astype(np.float32)
            M, _ = cv2.estimateAffinePartial2D(lm5, self.std, method=cv2.LMEDS)
            if M is None:
                return None
            out = cv2.warpAffine(img_bgr, M, (self.crop_size, self.crop_size), flags=cv2.INTER_LINEAR,
                                 borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))
            return out
        except Exception:
            return None

aligner = GPUFaceAligner(112)

# ---------------------- Consumer --------------------------

def on_msg(ch, method, properties, body):
    try:
        m = json.loads(body)
        name = m["object_name"]
        resp = minio_client.get_object(MINIO_BUCKET, name)
        data = resp.read(); resp.close(); resp.release_conn()
        img = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
        if img is None or img.size == 0:
            ch.basic_ack(method.delivery_tag)
            safe_remove(name)
            return
        job_q.put((name, img, method.delivery_tag), block=False)
    except Exception as e:
        print(f"[worker] on_msg error: {e}")
        ch.basic_nack(method.delivery_tag, requeue=True)

rmq_chan.basic_consume(queue=RMQ_QUEUE, on_message_callback=on_msg, auto_ack=False)

# ---------------------- Batch Döngüsü ----------------------

def process_pending(items: List[Tuple[str,np.ndarray,int]]):
    names = [n for (n,_,_) in items]
    imgs  = [im for (_,im,_) in items]
    tags  = [t for (_,_,t) in items]

    aligned = []
    for im in imgs:
        lms = fa.get_landmarks(im)
        a = aligner.align_face(im, lms[0]) if lms else None
        aligned.append(a)

    to_embed = [a for a in aligned if a is not None]
    embs = arc.infer(to_embed) if to_embed else np.empty((0,128), dtype=np.float32)
    it = iter(embs)

    for name, a, dtag in zip(names, aligned, tags):
        if a is None:
            rmq_chan.basic_ack(dtag)
            safe_remove(name)
            continue
        e = next(it, np.zeros((128,), np.float32))  # TODO: DB'ye yazılacaksa burada
        ok, buf = cv2.imencode(".jpg", a, [int(cv2.IMWRITE_JPEG_QUALITY), 90])
        if ok:
            minio_client.put_object(
                MINIO_BUCKET,
                f"{PROCESSED_PREFIX}aligned_{os.path.basename(name)}",
                BytesIO(buf), len(buf), content_type="image/jpeg"
            )
        rmq_chan.basic_ack(dtag)
        safe_remove(name)


def batch_worker_loop():
    pending = []
    last = time.time()
    while True:
        timeout = max(0.0, MAX_WAIT_MS/1000.0 - (time.time()-last))
        try:
            item = job_q.get(timeout=timeout)
            pending.append(item)
            if len(pending) >= BATCH_SIZE:
                process_pending(pending)
                pending = []
                last = time.time()
        except queue.Empty:
            if pending:
                process_pending(pending)
                pending = []
                last = time.time()


def safe_remove(object_name: str):
    try:
        minio_client.remove_object(MINIO_BUCKET, object_name)
        print(f"  -> silindi: {object_name}")
    except Exception as e:
        print(f"[WARN] remove {object_name}: {e}")


def main():
    print(f"[worker] BATCH={BATCH_SIZE} MAX_WAIT_MS={MAX_WAIT_MS} GPU_ID={GPU_ID}")
    t = threading.Thread(target=batch_worker_loop, daemon=True)
    t.start()
    try:
        rmq_chan.start_consuming()
    except KeyboardInterrupt:
        rmq_chan.stop_consuming()

if __name__ == "__main__":
    main()


# =============================
# Çalıştırma talimatları
# =============================
# 1) Altyapıyı ayağa kaldırın:
#    docker compose up -d   # RabbitMQ (http://localhost:15672 guest/guest) ve MinIO (http://localhost:9001)
# 2) Ortam değişkenlerini ayarlayın (gerekirse .env dosyasından kopyalayın)
# 3) DeepStream makinesinde video_process.py'yi çalıştırın:
#    python3 video_process.py /path/to/video.mp4
# 4) Worker makinesinde (GPU'lu) worker.py'yi çalıştırın:
#    python3 worker.py
# 5) Çıktılar MinIO'da:
#    raw-crops/: DS tarafından atılan kırpmalar
#    processed/: worker'ın hizalayıp isim başına 'aligned_' ile yükledikleri
